{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "tfkernal",
   "language": "python",
   "display_name": "tfKernal"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_dDGCPzE9TKN",
    "ExecuteTime": {
     "end_time": "2023-12-14T04:50:47.479540800Z",
     "start_time": "2023-12-14T04:50:47.434116200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Class path\n",
    "#Importing Librariespip\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Replace 'animals_path' with the actual path to your data directory\n",
    "animals_path = \"./DATASET\"\n",
    "\n",
    "# Create lists to store animal class labels and counts\n",
    "animal_labels = []\n",
    "animal_counts = []\n",
    "\n",
    "# Populate the lists with data\n",
    "for o in os.listdir(animals_path):\n",
    "    animal_labels.append(o)\n",
    "    animal_counts.append(len(os.listdir(os.path.join(animals_path, o))))\n",
    "\n",
    "# Create a bar plot to display the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(animal_labels, animal_counts)\n",
    "plt.title(\"Animals Distribution\")\n",
    "plt.xlabel(\"Animal Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "tJuvmCwACc1a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import math \n",
    "import re \n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "train_val_test_ratio= (0.7,0.1,0.2)\n",
    "test_folder = 'test/'\n",
    "train_folder ='train/'\n",
    "val_folder = 'val/'\n",
    "file_names = os.listdir(animals_path)\n",
    "# Remove existing folders if they exist \n",
    "for folder in [test_folder,train_folder,val_folder]:\n",
    "    if os.path.exists(folder) and os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "\n",
    "# Remake category folders in both Train and Test Folders\n",
    "\n",
    "for category in file_names:\n",
    "    os.makedirs(test_folder+category)\n",
    "    os.makedirs(train_folder+category)\n",
    "    os.makedirs(val_folder+category)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T04:51:53.872110400Z",
     "start_time": "2023-12-14T04:51:53.782952100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random  \n",
    "#Split Data by Train Ratio and copy files to correct directory \n",
    "for idx, category in enumerate(file_names):\n",
    "    file_list = os.listdir(animals_path + '/' + category)\n",
    "    random.shuffle(file_list)\n",
    "    train_ratio = math.floor(len(file_list) * train_val_test_ratio[0])\n",
    "    val_ratio = math.floor(len(file_list) * train_val_test_ratio[1])\n",
    "    train_list = file_list[:train_ratio]\n",
    "    val_list = file_list[train_ratio:train_ratio + val_ratio]\n",
    "    test_list = file_list[train_ratio + val_ratio:]\n",
    "    \n",
    "    for i, file in enumerate(train_list):\n",
    "        shutil.copy(animals_path + '/' + category + '/' + file, train_folder + '/' + category + '/' + file)\n",
    "        \n",
    "    sys.stdout.write('Moving %d train images to category folder %s' % (len(train_list), category)) \n",
    "    sys.stdout.write('\\n')\n",
    "    \n",
    "    for i, file in enumerate(val_list):\n",
    "        shutil.copy(animals_path + '/' + category + '/' + file, val_folder + '/' + category + '/' + file)\n",
    "        \n",
    "    sys.stdout.write('Moving %d validation images to category folder %s' % (len(val_list), category)) \n",
    "    sys.stdout.write('\\n')\n",
    "    \n",
    "    for i, file in enumerate(test_list):\n",
    "        shutil.copy(animals_path + '/' + category + '/' + file, test_folder + '/' + category + '/' + file)\n",
    "        \n",
    "    sys.stdout.write('Moving %d test images to category folder %s' % (len(test_list), category)) \n",
    "    sys.stdout.write('\\n')\n",
    "    \n",
    "print(\"Done\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator ,array_to_img,img_to_array,load_img\n",
    "# importing the library for data augmentation\n",
    "def data_augment(data_dir):\n",
    "    list_of_images = os.listdir(data_dir)\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=45,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\"\n",
    "    )\n",
    "\n",
    "    for img_name in list_of_images:\n",
    "        tmp_img_name = os.path.join(data_dir, img_name)\n",
    "\n",
    "        try:\n",
    "            img = load_img(tmp_img_name)\n",
    "            img = img_to_array(img)\n",
    "            img = img.reshape((1,) + img.shape)\n",
    "            #The flow function of this object generates batches of augmented data based on the provided parameters.\n",
    "            batch = datagen.flow(\n",
    "                img,\n",
    "                batch_size=1, #processing one image at a time for augmentation.\n",
    "                seed=21,\n",
    "                save_to_dir=data_dir,\n",
    "                save_prefix=img_name.split(\".JPG\")[0] + \"augmented\",\n",
    "                save_format=\"JPG\"\n",
    "            )\n",
    "            batch.next() # generates the augmented version of the current image within the loop.\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_name}: {str(e)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T21:38:00.650444Z",
     "start_time": "2023-12-08T21:38:00.624504900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes_to_augment = [\n",
    "    \"bear\", \"wild boar\"\n",
    "]\n",
    "for class_name in classes_to_augment:\n",
    "    print(\"Augmentation process happening:\", class_name)\n",
    "    data_dir= os.path.join(train_folder,class_name)\n",
    "    data_augment(data_dir)\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "path = \"./train\"\n",
    "\n",
    "# Create lists to store animal class labels and counts\n",
    "animal_labels = []\n",
    "animal_counts = []\n",
    "\n",
    "# Populate the lists with data\n",
    "for o in os.listdir(path):\n",
    "    animal_labels.append(o)\n",
    "    animal_counts.append(len(os.listdir(os.path.join(path, o))))\n",
    "\n",
    "# Create a bar plot to display the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(animal_labels, animal_counts)\n",
    "plt.title(\"Animals Distribution\")\n",
    "plt.xlabel(\"Animal Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet import preprocess_input as mobilenet_preprocess_input\n",
    "\n",
    "# Constants for MobileNet\n",
    "MOBILENET_WIDTH = 224\n",
    "MOBILENET_HEIGHT = 224\n",
    "BATCH_SIZE = 64\n",
    "test_dir = 'test/'\n",
    "train_dir = 'train/'\n",
    "val_dir = 'val/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T04:47:28.259851500Z",
     "start_time": "2023-12-14T04:47:28.247145800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train Dataset Generator with Augmentation for MobileNet\n",
    "print(\"\\nTraining Data Set for MobileNet\")\n",
    "train_generator_mobilenet = ImageDataGenerator(preprocessing_function=mobilenet_preprocess_input)\n",
    "#  preprocessing_function parameter is set to mobilenet_preprocess_input, which is likely a function used to preprocess images specifically for the MobileNet model.\n",
    "\n",
    "#generates a flow of augmented/processed image data from a directory. It creates a generator named train_flow_mobilenet \n",
    "\n",
    "train_flow_mobilenet = train_generator_mobilenet.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size=(MOBILENET_HEIGHT, MOBILENET_WIDTH),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Validation Dataset Generator with Augmentation for MobileNet\n",
    "print(\"\\nValidation Data Set for MobileNet\")\n",
    "val_generator_mobilenet = ImageDataGenerator(preprocessing_function=mobilenet_preprocess_input)\n",
    "val_flow_mobilenet = train_generator_mobilenet.flow_from_directory(\n",
    "    val_dir, \n",
    "    target_size=(MOBILENET_HEIGHT, MOBILENET_WIDTH),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train Dataset Generator with Augmentation for MobileNet\n",
    "print(\"\\nTest Data Set for MobileNet\")\n",
    "test_generator_mobilenet = ImageDataGenerator(preprocessing_function=mobilenet_preprocess_input)\n",
    "test_flow_mobilenet = train_generator_mobilenet.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(MOBILENET_HEIGHT, MOBILENET_WIDTH),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###Saved Images: You initially augment and save images to address class imbalance. This creates a more balanced dataset by artificially expanding the representation of minority classes.\n",
    "\n",
    "###Augmentation during Training: Then, during the training process, you employ an ImageDataGenerator with augmentation techniques. This allows for further variation in the data seen by the model during training, even though the images are not saved separately. The preprocessing_function parameter, like mobilenet_preprocess_input, is beneficial for correctly preparing the images for use with a specific neural network architecture.\n",
    "\n",
    "###By combining these approaches, not only address class imbalance by creating additional data but also provide further diversity to the model during training, enhancing its ability to generalize well to new, unseen data. This comprehensive approach can significantly improve the performance and robustness of your model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger\n",
    "from keras import optimizers, models\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras import applications\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Set the number of parallel execution units\n",
    "NUM_PARALLEL_EXEC_UNITS = 8\n",
    "#This line initializes a variable NUM_PARALLEL_EXEC_UNITS to 8, indicating the desired number of CPU cores or threads for parallel execution\n",
    "\n",
    "# Set Performance Parameters for MKL and Tensorflow using Keras backend\n",
    "# Configuring TensorFlow Session\n",
    "config = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=NUM_PARALLEL_EXEC_UNITS,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "### TensorFlow uses a session to execute operations. Here, we configure TensorFlow to use 8 threads (NUM_PARALLEL_EXEC_UNITS) for intra-operation parallelism (operations within a graph) and 1 thread for inter-operation parallelism (operations between graphs). tf.ConfigProto defines the session configuration, and K.set_session(session) sets this configuration for Keras backend.\n",
    "\n",
    "\n",
    "###K.set_session(session) sets this configuration for Keras backend.\n",
    "\n",
    "# Setting MKL and OpenMP Environment Variables:\n",
    "# MKL and OpenMP\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(NUM_PARALLEL_EXEC_UNITS)\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"] = \"granularity=fine,verbose,compact,1\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize mobilenet with transfer learning\n",
    "### Removing Top Layers (include_top=False): The top layers of a CNN typically involve the final fully connected layers responsible for classification. When include_top=False is used, these classification layers are removed, leaving the convolutional base intact.\n",
    "base_model = applications.MobileNet (weights=' imagenet',\n",
    "include_top=False,\n",
    "input_shape=(MOBILENET_WIDTH, MOBILENET_HEIGHT, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#add a global spatial average pooling layer\n",
    "x= base_model.output\n",
    "x = GlobalAveragePooling2D() (x)\n",
    "###Global Average Pooling Layer: It reduces the spatial dimensions of the previous layer (output of the pre-trained MobileNet) to a vector by taking the average of each channel. This helps in reducing the total number of parameters and provides a more abstract, condensed representation of the features.\n",
    "# and a dense layer\n",
    "x = Dense(1024, activation= 'relu') (x)\n",
    "predictions = Dense(len(train_flow_mobilenet.class_indices), activation='softmax') (x)\n",
    "\n",
    "###Dense Layer (ReLU Activation): A fully connected layer with 1024 neurons and ReLU activation function is added. This layer helps in learning high-level features from the abstract representations obtained from previous layers.\n",
    "\n",
    "###Output Layer: Another Dense layer is added with a number of neurons equal to the number of classes in the training dataset. It uses softmax activation to output class probabilities.\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions) # The Model() function is used to define the architecture of the overall model by specifying inputs as the input layer of the pre-trained MobileNet (base_model.input) and outputs as the final predictions\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compile the model (should be done after setting layers to non-trainable)\n",
    "model. compile(optimizer=optimizers.Adam(r=0.001), metrics=['accuracy', 'top_k_categorical accuracy'], loss=' categorical_crossentropy') \n",
    "#  The learning rate is a hyperparameter that determines the step size taken during the optimization process to update the weights of a neural network.\n",
    "model. summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Freezing Layers in Transfer Learning\n",
    "\n",
    "The reason for explicitly freezing the layers of the `base_model` even though an optimizer with a learning rate is being used is to ensure that only the added layers (top layers) receive updates during training.\n",
    "\n",
    "When compiling the model with an optimizer and a learning rate, such as using the Adam optimizer in the code:\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, CSVLogger\n",
    "\n",
    "top_layers_file_path = \"top_layers.mn.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(top_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "tb = TensorBoard(log_dir='./logs', write_graph=True, update_freq='batch')\n",
    "early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=5)\n",
    "csv_logger = CSVLogger('./logs/mn-log.csv', append=True)\n",
    "\n",
    "# Assuming `model` is already defined\n",
    "history = model.fit_generator(train_flow_mobilenet,\n",
    "                              epochs=3,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_flow_mobilenet,\n",
    "                              validation_steps=math.ceil(val_flow_mobilenet.samples / val_flow_mobilenet.batch_size),\n",
    "                              steps_per_epoch=math.ceil(train_flow_mobilenet.samples / train_flow_mobilenet.batch_size),\n",
    "                              callbacks=[checkpoint, early, tb, csv_logger])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
